{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7\n",
    "\n",
    "This notebook is based on Chapter 6 tutorial by F. Menczer, S. Forunato, C.A. Davis, *A First Course in Network Science* (Cambridge 2020), available at: https://cambridgeuniversitypress.github.io/FirstCourseNetworkScience/.\n",
    "The contents of the tutorials have been adapted by KAK.\n",
    "\n",
    "Contents:\n",
    "\n",
    "1. Tutorials\n",
    "\n",
    "    1.1 Partitions\n",
    "\n",
    "    1.2. Modularity\n",
    "\n",
    "    1.3. Zachary's Karate Club\n",
    "\n",
    "    1.4. Girvan-Newman clustering algorithm\n",
    "\n",
    "2. Exercises\n",
    "\n",
    "    2.1 Exercise 1: Girvan-Newman algorithm\n",
    "\n",
    "    2.2 Exercise 2: Kernighan-Lin algorithm\n",
    "\n",
    "    2.3 Exercise 3: Modularity in Gephi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tutorials\n",
    "\n",
    "### 1.1 Partitions\n",
    "\n",
    "During the lecture we've learned that a **partition** of a graph is a separation of its nodes into disjoint groups. \n",
    "Formally, a partition is a list of sets such that every node is in exactly one set.\n",
    "\n",
    "In Network Science there are two partitions which are referred to as the trivial partitions:\n",
    "\n",
    "1. The partition with one set containing every node (Singleton Partition).\n",
    "2. The partition with N sets, each containing a single node (Partition of Singletons).\n",
    "\n",
    "A valid partition thus contains between 1 and N sets.  \n",
    "\n",
    "Consider the following graph representing two separate groups of students who interact with each other internally on regular basis (as they are in the same study programme and take the same classes), but never interact with the other group. \n",
    "Let one group be TNAH and the other HN.  \n",
    "\n",
    "Let's assume that in each group there is one student who is involved in the Student Enterprise of École nationale des Chartes, CartaData. Let is be Ann for TNAH and Zack for HN.  Ann and Zack interact with each other within CartaData creating a link between the two student groups.\n",
    "\n",
    "This can be visualised as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "nx.add_cycle(G, [\"Ann\", \"Bob\", \"Camilla\", \"Dave\"])\n",
    "nx.add_cycle(G, [\"Uma\", \"Yige\", \"Walter\", \"Zack\"])\n",
    "G.add_edge(\"Ann\", \"Zack\")\n",
    "\n",
    "nx.draw(G, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's think that we would like to identify the communities within our network. How would you like to analyse and identify the relationships between the students? \n",
    "\n",
    "You could partition the nodes into three groups in the following way: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = [\n",
    "    {\"Bob\", \"Camilla\", \"Dave\"},\n",
    "    {\"Uma\", \"Yige\", \"Walter\"},\n",
    "    {\"Ann\", \"Zack\"},\n",
    "]\n",
    "print(partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that every node in the graph can be in exactly one of the sets in the partition, so if you want to somehow highlight the CartaData relationship, you have to put Ann and Zack into a separate bag.\n",
    "\n",
    "Using NetworkX and its function `community.is_partition` we can verify that our partition is valid (i.e. one partition per node):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.community.is_partition(G, partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When developing community detection algorithms, we often make use of a *partition map*, which is a dictionary mapping node names to a partition index. This is useful for quickly comparing if two nodes are in the same cluster in the partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_map = {}\n",
    "for idx, cluster_nodes in enumerate(partition):\n",
    "    for node in cluster_nodes:\n",
    "        partition_map[node] = idx\n",
    "\n",
    "partition_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dictionary, the keys are the node names and two nodes will have the same value if they are in the same partition.\n",
    "Let's test  (expecting only True or False answer) whether \"Ann\" and \"Bob\" are in the same partition: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_map[\"Ann\"] == partition_map[\"Bob\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize our partition by drawing the graph with nodes colored by their partition membership:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_colors = [partition_map[n] for n in G.nodes]\n",
    "        \n",
    "nx.draw(G, node_color=node_colors, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, but what if we don't want to do this manually (and we never do)? \n",
    "\n",
    "We've learned during the lecture that there are various methods of partitioning our graph; one of them is bisection (i.e.\n",
    "we want to partition a graph into two blocks). \n",
    "\n",
    "We can use the Kernighan–Lin algorithm, which is included in the NetworkX function: `kernighan_lin_bisection` (G, partition=None, max_iter=10, weight='weight', seed=None), described here: https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.kernighan_lin.kernighan_lin_bisection.html\n",
    "\n",
    "Let's use it on our graph. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_partition = list(nx.community.kernighan_lin_bisection(G))\n",
    "print(new_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_partition_map = {}\n",
    "for idx, cluster_nodes in enumerate(new_partition):\n",
    "    for node in cluster_nodes:\n",
    "        new_partition_map[node] = idx\n",
    "print(\"New partition:\", new_partition_map)\n",
    "print(\"Is partitionL\", nx.community.is_partition(G, new_partition))\n",
    "\n",
    "new_node_colors = [new_partition_map[n] for n in G.nodes]\n",
    "nx.draw(G, node_color=new_node_colors, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So by bisecting our graph (dividing the graph into two partitions), we are able to distinguish two groups of nodes corresponding to TNAH & HN students. However, we have no way of finding out that Ann and Zack worked together in CartaData.  \n",
    "\n",
    "Think about the question how we could represent the existence of CartaData? \n",
    "\n",
    "Note your answer below before you move to the next section .  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Answer_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Modularity\n",
    "\n",
    "At a high level, network community detection consists of finding a partition that achieves good separation between the groups of nodes. Before we get into how to find good partitions of a graph, we need an objective -- a way to measure how good the partition is. Modularity is one such objective function.\n",
    "\n",
    "The modularity of a graph partition compares the number of intra-group edges with a random baseline. Higher modularity scores correspond to a higher proportion of intra-group edges, therefore fewer inter-group edges and better separation of groups.\n",
    "\n",
    "Box 6.1 in the textbook describes how modularity is calculated. Here, let's try to calculate modularity for weighted undirected networks (Equation 6.6). It is calculated using the total weight of the links of the network `W`, the total weight of the internal links of a given cluster `W_c`, and the total strength of the nodes of the cluster `s_c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will define here our own function to calculate modularity. \n",
    "def my_modularity(G, part):\n",
    "    W = sum(G.edges[v, w].get('weight', 1) for v, w in G.edges) # sum up all edge weights in the graph (if an edge has no weight attribute, assume weight of 1)\n",
    "    summation = 0\n",
    "    for cluster_nodes in part: # Iterate through each community in the partition.\n",
    "        s_c = sum(G.degree(n, weight='weight') for n in cluster_nodes) # Compute the sum of weighted degrees (strengths) in the community\n",
    "        C = G.subgraph(cluster_nodes)   # Use subgraph to count only internal links\n",
    "        #Compute the total internal edge weight in the community \n",
    "        W_c = sum(C.edges[v, w].get('weight', 1) for v, w in C.edges)\n",
    "        summation += W_c - s_c ** 2 / (4 * W)\n",
    "    return summation / W\n",
    "\n",
    "part = new_partition # You can change between `partition` and `new_partition` defined above to see how the modularity changes and consider which one is better? \n",
    "my_modularity(G, part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values we get as a result of this calculation should be 0.38 for the partition we got through bisection (dividing our nodes into two groups of nodes, `new_partition`), and 0.22 for the partition we manually introduced (dividing our network into three groups of nodes `partition`). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NetworkX function\n",
    "\n",
    "NetworkX provides a modularity function `community.quality.modularity` that is more efficient than ours, but its result will be the same as ours. \n",
    "\n",
    "Test it for both scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.community.quality.modularity(G, new_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Remember:* \n",
    "\n",
    "Higher modularity (~0.3 to 0.7) → Stronger community structure.\n",
    "\n",
    "Lower modularity (~0.0 to 0.1) → Weak or no community structure.\n",
    "\n",
    "Negative modularity → Worse than random clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Zachary's Karate Club"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When writing and testing community-detection algorithms, it helps to make use of benchmark networks: graphs with a known, \"natural\" community structure. Perhaps the most famous benchmark graph is Zachary's Karate Club. It contains 34 nodes, representing members of a karate club whose interactions were monitored over a period of three years by researchers. Links in this graph connect individuals interacting outside club activities, a proxy for social ties.\n",
    "\n",
    "During the course of the study, a conflict between the instructor Mr. Hi (node 0) and the president, or Officer (node 33) led to a split of the club into separate groups led by Mr. Hi and Officer. In this case we know whom each member of the group followed after the split, providing empirical community labels: those members who followed Mr. Hi are said to be one community and those following the Officer make up the other.\n",
    "\n",
    "For this graph, we assume that the post-split group composition was largely driven by the social ties: members of the same friend groups would want to be part of the same club after the split. We thus expect a good community-detection algorithm to predict the post-split group composition with high accuracy.\n",
    "\n",
    "Zachary's karate club is such a popular benchmark graph that it has its own function in NetworkX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = nx.karate_club_graph()\n",
    "nx.draw(K, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each node in a NetworkX graph has a dictionary of *attributes* associated with it. This dictionary can hold arbitrary data about a node. We can get the attributes for a single node by giving the node name to the `nodes` object.\n",
    "\n",
    "Each node in this graph has a `'club'` attribute, indicating whether the member followed the instructor or the president after the split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.nodes[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize these labels by coloring each node according to its `'club'` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = nx.karate_club_graph()\n",
    "club_color = {\n",
    "    'Mr. Hi': 'orange',\n",
    "    'Officer': 'lightblue',\n",
    "}\n",
    "node_colors = [club_color[K.nodes[n]['club']] for n in K.nodes]\n",
    "nx.draw(K, node_color=node_colors, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This separation looks good, in that there are relatively few inter-community links as opposed to intra-community links. Let's create a graph partition based on these labels and measure its modularity.\n",
    "\n",
    "We can do this by creating a dictionary of two sets, one for each value of the nodes' `'club'` attribute, then assigning the nodes to the corresponding set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "    'Mr. Hi': set(),\n",
    "    'Officer': set(),\n",
    "}\n",
    "\n",
    "for n in K.nodes:\n",
    "    club = K.nodes[n]['club']\n",
    "    groups[club].add(n)\n",
    "    \n",
    "groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the dictionary's `.values()` method, we can get a list of sets that define our partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_partition = list(groups.values())\n",
    "empirical_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.community.is_partition(K, empirical_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our partition is indeed a valid partition, we can get the modularity of this partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.community.quality.modularity(K, empirical_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a relatively high modularity, which is what we expect.\n",
    "\n",
    "### Comparison to a random partition\n",
    "\n",
    "For the sake of comparison, let's generate a random partition of this network and check its modularity. We would expect a modularity close to zero in this case.\n",
    "\n",
    "First we generate a sample of 17 nodes, half the total number of nodes, and assign them to one community. Our second community then includes the nodes in the graph not in the first community. We can use some set arithmetic to do this concisely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_nodes = random.sample(list(K.nodes), 17)\n",
    "#Create a list of two sets\n",
    "# The first set contains the 17 randomly selected nodes.\n",
    "# The second set contains all other nodes in the graph.\n",
    "random_partition = [set(random_nodes),\n",
    "                    set(K.nodes) - set(random_nodes)] \n",
    "random_partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize this partition and observe that the communities are much less natural-looking, as we would expect from a random assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_node_colors = ['orange' if n in random_nodes else 'lightblue' for n in K.nodes]\n",
    "nx.draw(K, node_color=random_node_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we can test the modularity of this partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.community.quality.modularity(K, random_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a random process the modularity won't be exactly zero, but it should be fairly close. Go ahead and repeat the process of generating a random partition and testing its modularity -- it will fluctuate around its mean value of zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.4. Girvan-Newman clustering\n",
    "\n",
    "Our task in this part will be to implement the Girvan-Newman clustering algorithm. Since NetworkX can do the heavy lifting for us -- computing betweenness centrality -- the code part of the task is relatively straightforward. Most of our effort here is spent interpreting and explaining intermediate results.\n",
    "\n",
    "Let's recall from the lecture (and/or textbook) that the Girvan-Newman clustering algorithm helps us to:\n",
    "\n",
    "1. Create a partition sequence\n",
    "  1. Calculate the betweenness centrality for all links.\n",
    "  2. Remove the link with largest betweenness and create a partition using connected components.\n",
    "  3. Recalculate the betweenness centrality of the links of the resulting graph.\n",
    "  4. Repeat from step two until no links remain.\n",
    "2. Evaluate each partition in the sequence and choose the one with the highest modularity.\n",
    "\n",
    "During this process, the number of connected components in the graph will increase monotonically as clusters are broken up. Since we are removing one link at a time, the number of connected components can increase by at most one between steps in the sequence -- it's not possible for a single edge to connect more than two nodes, and thus components.\n",
    "\n",
    "We hope that the resulting partition of the graph will approximate its underlying community structure. We'll use the Karate Club graph here because we know the ground-truth community labels and can compare the result obtained from the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1 Create a partition sequence\n",
    "##### 1.4.1.1. Calculate the betweenness centrality for all links\n",
    "\n",
    "NetworkX does the heavy lifting here. All we need to do is understand the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.edge_betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dictionary has edge tuples as the keys, and each associated value is the betweenness centrality of that edge. The algorithm to compute the edge betweenness of all edges in a graph costs about the same as calculating it for a single edge, so we'll make use of this dictionary with the computed values for every edge.\n",
    "\n",
    "Once computed for all edges, we can easily get the associated betweenness for a single edge. For example, to get the edge betweenness of the edge between nodes 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_edge_betweenness = nx.edge_betweenness_centrality(G)\n",
    "my_edge_betweenness[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that dictionaries also have the `.get` method. This will be used in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_edge_betweenness.get((0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.1.2. Remove the link with largest betweenness...\n",
    "\n",
    "Given this dictionary of betweenness values for each edge, we can make use of Python's inbuilt `max` function to give us the key in this dictionary with the greatest value. Since there is a key in the dictionary for each edge in the graph, the following two expressions are equivalent, but the second one is probably more explicit as to what we're doing with this statement.\n",
    "\n",
    "I'm using the name `my_edge_betweenness` to make clear that this is a dictionary we've named and not a NetworkX function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(my_edge_betweenness, key=my_edge_betweenness.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(G.edges(), key=my_edge_betweenness.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is then the edge we want to remove at this step in the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_edge_betweenness = nx.edge_betweenness_centrality(G)\n",
    "most_valuable_edge = max(G.edges(), key=my_edge_betweenness.get)\n",
    "print(\"The most valuable edge (with the highest betweenness centrality) is:\",  most_valuable_edge)\n",
    "print(\"Unpacked:\",*most_valuable_edge)\n",
    "G.remove_edge(*most_valuable_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"splat\" (`*`-operator) in the last statement above `G.remove_edge(*most_valuable_edge)` performs tuple unpacking into the arguments of a function. For example, if our most valuable edge is `(0, 31)`,\n",
    "\n",
    "    G.remove_edge(*most_valuable_edge)\n",
    "is the same as\n",
    "    \n",
    "    G.remove_edge(most_valuable_edge[0], most_valuable_edge[1])\n",
    "or\n",
    "\n",
    "    G.remove_edge(0, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ...and create a partition using connected components\n",
    "\n",
    "This is almost a too simple example, because the `nx.connected_components()` function gives us almost exactly what we want: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.connected_components(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just have to remember to ask for it in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nx.connected_components(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember: a partition is a list of sets where every node is in exactly one of these sets. This is just what we have here, although it's a bit boring since we've only removed one edge and so there is still one connected component. If you like, you can try running the previous two cells a few times until you have more than one connected component so you can see what that looks like.\n",
    "\n",
    "Note that this feature whereby the connected components correspond exactly to our putative community labels is particular to the Girvan-Newman algorithm: other clustering algorithms may use different ways of generating their partitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.1.3. Recalculate the betweenness centrality of the links of the resulting graph.\n",
    "##### 1.4.1.4. Repeat from step two until no links remain.\n",
    "\n",
    "This implies that we need a loop to repeat this process $L$ times, once for each edge, and that we should keep track of the partitions generated. Straightforward stuff. We'll start with a fresh Karate Club graph since we removed some edges above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "partition_sequence = []\n",
    "for _ in range(G.number_of_edges()):\n",
    "    my_edge_betweenness = nx.edge_betweenness_centrality(G)\n",
    "    most_valuable_edge = max(G.edges(), key=my_edge_betweenness.get)\n",
    "    G.remove_edge(*most_valuable_edge)\n",
    "    my_partition = list(nx.connected_components(G))\n",
    "    partition_sequence.append(my_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the idiomatic construction of this `for` loop. Using `_` as the name for the loop variable tells the reader that we don't expect to do anything with the loop variable -- we just want to perform a task a specific number of times. One might be tempted to use a `while` loop here, but that way lie dragons: a mistake in a `while` loop can lead to infinite loops which are a headache.\n",
    "\n",
    "If we've done this right, we should have a partition for each step of the process, *i.e.* one for each edge in the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(partition_sequence), nx.karate_club_graph().number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we started with a connected graph, removing one edge probably doesn't disconnect the graph, so our first partition probably only has one community:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(partition_sequence[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and the last partition should also be trivial, with each node in its own community:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(partition_sequence[-1]), nx.karate_club_graph().number_of_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 Evaluate the modularity of each partition in the sequence\n",
    "\n",
    "We now have a sequence of partitions and a function to calculate the modularity of a partition. This is a great time to use a list comprehension!\n",
    "If you need a reminder, check out W3schools tutorial: https://www.w3schools.com/python/python_lists_comprehension.asp \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "modularity_sequence = [my_modularity(G, p) for p in partition_sequence] # Here we are calling out own function `my_modularity` we defined above \n",
    "modularity_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sequence is then the modularity of the partition at each step in the algorithm. The first several entries in this sequence are effectively zero while there is only one community/component, then it jumps up once there is more than one community. We can use pyplot to visualize this relationship:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(modularity_sequence)\n",
    "plt.ylabel('Modularity')\n",
    "plt.xlabel('Algorithm step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the partition with highest modularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually, we see a peak in the modularity sequence. This is the partition that maximizes modularity, and thus the output of the algorithm. We can use the `max` function to get the partition with highest modularity. Ideally we want to write the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "best_partition = max(partition_sequence, key=nx.community.quality.modularity) # This will give us an error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...but we receive an error. Recall that a key function must take exactly one argument, the item in the sequence being evaluated, but the modularity function takes two arguments: the graph and the partition. We can fix this by writing a single-argument function to use as the key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_modularity1(partition):\n",
    "    return nx.community.quality.modularity(G, partition)\n",
    "best_partition = max(partition_sequence, key=my_modularity1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced Pythonauts will see a differet solution to this using the `zip` function to align the previously-generated partition & modularity sequences, but this solution is more explicit.\n",
    "\n",
    "So after all that work, what is the best partition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! The partition of the karate club graph with highest modularity actually has five components! Let's visualize them, using our code for partition maps we wrote back at the beginning of this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_partition_map(partition):\n",
    "    partition_map = {}\n",
    "    for idx, cluster_nodes in enumerate(partition):\n",
    "        for node in cluster_nodes:\n",
    "            partition_map[node] = idx\n",
    "    return partition_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_partition_map = create_partition_map(best_partition)\n",
    "\n",
    "node_colors = [best_partition_map[n] for n in G.nodes()]\n",
    "nx.draw(G, with_labels=True, node_color=node_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly how good is this five-community clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.community.quality.modularity(G, best_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's higher than the \"ground truth\" communities we evaluated in section 3, which is a good sign, but for the specific problem of trying to predict the post-split community membership, a clustering into five groups is useless to us.\n",
    "\n",
    "### Get the best partition with a given number of communities\n",
    "\n",
    "One of the most useful parts of the Girvan-Newman algorithm is that it is also useful when we have a specific number of clusters we want. In this case, we know the karate club split into two groups, so let's get the partition in the sequence with two components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition in partition_sequence:\n",
    "    if len(partition) == 2:\n",
    "        two_cluster_partition = partition\n",
    "        break\n",
    "\n",
    "two_cluster_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_cluster_partition_map = create_partition_map(two_cluster_partition)\n",
    "\n",
    "node_colors = [two_cluster_partition_map[n] for n in G.nodes()]\n",
    "nx.draw(G, with_labels=True, node_color=node_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good is this partition? We can get its modularity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.community.quality.modularity(G, two_cluster_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good -- comparable to the ground truth community labels. Let's compare these side-by-side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # Remember for this to run, you need matplotlib installed in the virtual environment in which you're running your NA notebooks\n",
    "\n",
    "pos = nx.layout.spring_layout(G)\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "two_cluster_partition_map = create_partition_map(two_cluster_partition)\n",
    "node_colors = [two_cluster_partition_map[n] for n in G.nodes()]\n",
    "nx.draw(G, with_labels=True, node_color=node_colors, pos=pos)\n",
    "plt.title('Predicted communities')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "node_colors = [G.nodes[n]['club'] == 'Officer' for n in G.nodes()]\n",
    "nx.draw(G, with_labels=True, node_color=node_colors, pos=pos)\n",
    "plt.title('Actual communities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the predicted community labels are pretty accurate, only differing on a couple nodes that, visually, seem like they could plausibly belong to either group. \n",
    "\n",
    "Zachary's original paper even explains the practical considerations of one of these mispredicted nodes: node 8. \n",
    "\n",
    "Node 8 (or individual 9 in the original paper) was a supporter of the officer, but this individual was very near receiving a black belt from Mr. Hi and therefore did not want to leave the group. \n",
    "\n",
    "Read the original paper of Zachary (1977) here: https://www.researchgate.net/publication/248519014_An_Information_Flow_Model_for_Conflict_and_Fission_in_Small_Groups1/link/55428c610cf234bdb21a1658/download?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6InB1YmxpY2F0aW9uIiwicGFnZSI6InB1YmxpY2F0aW9uIn19\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NetworkX Function\n",
    "\n",
    "An attentive reader might note that there may be several bipartitions in the partition sequence we generated. \n",
    "\n",
    "We assert the following to be true:\n",
    "\n",
    "1. For every integer 1 to N, the number of nodes, there is a partition in the sequence with that number of clusters\n",
    "2. Every partition in the sequence with the same number of clusters is the same\n",
    "\n",
    "As a consequence of these being true, optimized implementations of Girvan-Newman clustering will only store one partition for each number of clusters. This is how the implementation in NetworkX works, only providing one partition for each number of communities greater than one.\n",
    "\n",
    "`nx.community.girvan_newman(G)` will generate a sequence containing one partition of each size greater than one. \n",
    "\n",
    "Below we can see the first five, and they are the same as those we generated using our own modularity function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nx.community.girvan_newman(G))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exercises \n",
    "### Exercise 2.1: Girvan-Newman clustering\n",
    "\n",
    "How would you check whether indeed all bipartitions in the list of all possible partitions we created with my_modularity are the same (our `partition_sequence`)? \n",
    "\n",
    "Write a code that checks how many bipartitions are there and then checks whether or not they are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Kernighan-Lin algorithm \n",
    "Find the best bisection of Zachary's karate club network by applying Kernighan-Lin algorithm. \n",
    "You can use the `kernighan_lin_bisection()` of NetworkX. \n",
    "\n",
    "What is the modularity of this partition? \n",
    "\n",
    "Generate two plots, one with the benchmark and one with the Kernighan clustering. \n",
    "Compare the resulting from this bipartition with the benchmark (the natural split that took place in the karate network).\n",
    "\n",
    "What are the differences? \n",
    "\n",
    "What does they tell us about the clustering algorithms in social networks? \n",
    "\n",
    "What do it tell us about the nodes in question? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.3: Modularity in Gephi\n",
    "\n",
    "Export the network data in the format of your choice and import it into Gephi. Test how the modularity function works there. \n",
    "Does it use any of the functions we talked about today? \n",
    "What are the differences? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NAenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
